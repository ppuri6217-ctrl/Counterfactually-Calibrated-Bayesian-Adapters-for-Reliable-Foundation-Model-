{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1508992,"sourceType":"datasetVersion","datasetId":888463}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kaggle-optimized C²BA Implementation for UCI Heart Disease\n# This script is designed to run directly in Kaggle notebooks\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# PyTorch imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# Scikit-learn imports  \nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\nfrom sklearn.calibration import calibration_curve\n\n# Other imports\nimport scipy.stats as stats\nfrom scipy.spatial.distance import pdist, squareform\nimport warnings\nimport os\nimport sys\nfrom pathlib import Path\n\nwarnings.filterwarnings('ignore')\n\n# Kaggle-specific configurations\nplt.style.use('default')\nsns.set_palette(\"husl\")\n\n# Set random seeds for reproducibility\ndef set_random_seeds(seed=42):\n    \"\"\"Set all random seeds for reproducibility\"\"\"\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    # For deterministic behavior (may impact performance)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_random_seeds(42)\n\n# Kaggle dataset loading function\ndef load_heart_disease_data():\n    \"\"\"Load UCI Heart Disease dataset - adaptable to Kaggle input paths\"\"\"\n    \n    # Try multiple potential Kaggle input paths\n    potential_paths = [\n        '/kaggle/input/heart-disease-data/heart_disease_uci.csv',\n        '/kaggle/input/heart-disease/heart.csv', \n        '/kaggle/input/uci-heart-disease/heart.csv',\n        '/kaggle/input/heart.csv',\n        'heart.csv'  # If uploaded directly\n    ]\n    \n    df = None\n    for path in potential_paths:\n        try:\n            if os.path.exists(path):\n                df = pd.read_csv(path)\n                print(f\"✓ Successfully loaded data from: {path}\")\n                break\n        except Exception as e:\n            continue\n    \n    # If no dataset found, create synthetic data for demonstration\n    if df is None:\n        print(\"⚠ No heart disease dataset found in standard Kaggle paths.\")\n        print(\"Creating synthetic dataset for demonstration...\")\n        df = create_synthetic_heart_data()\n    \n    return df\n\ndef create_synthetic_heart_data():\n    \"\"\"Create synthetic UCI Heart Disease-like dataset\"\"\"\n    np.random.seed(42)\n    n_samples = 1025  # Realistic size similar to UCI dataset\n    \n    # Create realistic synthetic data\n    data = {\n        'age': np.random.normal(54, 9, n_samples).clip(29, 77).astype(int),\n        'sex': np.random.binomial(1, 0.68, n_samples),  # Male bias as in real data\n        'cp': np.random.choice([0, 1, 2, 3], n_samples, p=[0.47, 0.16, 0.29, 0.08]),\n        'trestbps': np.random.normal(131, 17, n_samples).clip(94, 200).astype(int),\n        'chol': np.random.normal(246, 51, n_samples).clip(126, 564).astype(int),\n        'fbs': np.random.binomial(1, 0.15, n_samples),\n        'restecg': np.random.choice([0, 1, 2], n_samples, p=[0.48, 0.48, 0.04]),\n        'thalach': np.random.normal(149, 22, n_samples).clip(71, 202).astype(int),\n        'exang': np.random.binomial(1, 0.33, n_samples),\n        'oldpeak': np.random.exponential(1.04, n_samples).clip(0, 6.2).round(1),\n        'slope': np.random.choice([0, 1, 2], n_samples, p=[0.21, 0.14, 0.65]),\n        'ca': np.random.choice([0, 1, 2, 3, 4], n_samples, p=[0.59, 0.21, 0.12, 0.06, 0.02]),\n        'thal': np.random.choice([0, 1, 2, 3], n_samples, p=[0.02, 0.55, 0.36, 0.07])\n    }\n    \n    # Create target variable with realistic medical correlations\n    risk_factors = (\n        0.02 * data['age'] +\n        0.5 * (data['cp'] == 0) +  # Typical angina increases risk\n        0.3 * data['exang'] +\n        0.4 * (data['thal'] == 2) +  # Reversible defect\n        0.2 * data['oldpeak'] +\n        -0.01 * data['thalach'] +  # Higher heart rate = lower risk\n        0.3 * (data['ca'] > 0) +  # Major vessels\n        0.2 * data['sex'] +  # Male higher risk\n        np.random.normal(0, 0.8, n_samples)\n    )\n    \n    # Convert to binary (0=no disease, 1=disease) - more realistic for UCI data\n    data['target'] = (risk_factors > np.percentile(risk_factors, 55)).astype(int)\n    \n    df = pd.DataFrame(data)\n    \n    # Add some missing values to make it realistic\n    missing_cols = ['ca', 'thal']\n    for col in missing_cols:\n        missing_mask = np.random.random(len(df)) < 0.02  # 2% missing\n        df.loc[missing_mask, col] = np.nan\n    \n    print(f\"✓ Created synthetic dataset with {len(df)} samples\")\n    print(f\"Target distribution: {df['target'].value_counts().to_dict()}\")\n    \n    return df\n\nclass HeartDiseaseDataset(Dataset):\n    \"\"\"Custom dataset for UCI Heart Disease with feature engineering\"\"\"\n    \n    def __init__(self, features, targets, transform=None):\n        self.features = torch.FloatTensor(features)\n        self.targets = torch.LongTensor(targets)\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, idx):\n        x = self.features[idx]\n        y = self.targets[idx]\n        \n        if self.transform:\n            x = self.transform(x)\n        \n        return x, y\n\nclass DataProcessor:\n    \"\"\"Comprehensive data preprocessing pipeline\"\"\"\n    \n    def __init__(self):\n        self.scaler = StandardScaler()\n        self.label_encoders = {}\n        self.feature_stats = {}\n        self.embedding_dims = {\n            'sex': 4, 'dataset': 6, 'cp': 6, 'restecg': 4, 'slope': 4, 'thal': 4\n        }\n        \n    def create_embeddings(self, df, categorical_cols):\n        \"\"\"Create embedding matrices for categorical features\"\"\"\n        embeddings = {}\n        for col in categorical_cols:\n            if col in df.columns:\n                unique_vals = df[col].nunique()\n                embed_dim = min(50, int(unique_vals**0.25) * 4)\n                embeddings[col] = nn.Embedding(unique_vals, embed_dim)\n        return embeddings\n    \n    def engineer_features(self, df):\n        \"\"\"Advanced feature engineering\"\"\"\n        df_eng = df.copy()\n        \n        # Polynomial interactions\n        interactions = [\n            ('age', 'trestbps'),\n            ('age', 'thalch'), \n            ('chol', 'trestbps'),\n            ('oldpeak', 'slope'),\n            ('cp', 'exang')\n        ]\n        \n        for feat1, feat2 in interactions:\n            if feat1 in df_eng.columns and feat2 in df_eng.columns:\n                df_eng[f'{feat1}_{feat2}_interaction'] = df_eng[feat1] * df_eng[feat2]\n        \n        # Missing value indicators\n        for col in df_eng.columns:\n            if df_eng[col].isna().sum() > len(df_eng) * 0.05:  # >5% missing\n                df_eng[f'{col}_missing'] = df_eng[col].isna().astype(int)\n        \n        return df_eng\n    \n    def preprocess_data(self, df, is_training=True):\n        \"\"\"Complete preprocessing pipeline - adapted for real UCI heart data structure\"\"\"\n        df_processed = df.copy()\n        \n        # Handle common UCI heart dataset column names\n        target_col = 'target' if 'target' in df.columns else 'num'\n        \n        # Standardize column names if needed\n        column_mapping = {\n            'num': 'target',  # UCI dataset sometimes uses 'num' for target\n        }\n        df_processed = df_processed.rename(columns=column_mapping)\n        \n        # Ensure target column exists\n        if target_col not in df_processed.columns and 'target' not in df_processed.columns:\n            if 'num' in df_processed.columns:\n                df_processed['target'] = df_processed['num']\n            else:\n                raise ValueError(\"No target column found. Expected 'target' or 'num'\")\n        \n        # For multi-class, convert to binary for simplicity in this demo\n        if 'target' in df_processed.columns:\n            max_target_value = df_processed['target'].max()\n            if pd.isna(max_target_value):\n                max_target_value = 0\n            if max_target_value > 1:  # Now comparing scalar values\n                df_processed['target'] = (df_processed['target'] > 0).astype(int)\n                # Now max_target_value is a scalar, safe to compare\n                if max_target_value > 1:\n                    df_processed['target'] = (df_processed['target'] > 0).astype(int)\n            else:\n                # All values are NaN, set default\n                df_processed['target'] = 0\n            \n        # Feature engineering\n        df_processed = self.engineer_features(df_processed)\n        \n        # Separate feature types\n        feature_cols = [col for col in df_processed.columns if col != 'target']\n        continuous_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n        binary_cols = ['sex', 'fbs', 'exang']\n        categorical_cols = ['cp', 'restecg', 'slope', 'ca', 'thal']\n        \n        # Filter to existing columns\n        continuous_cols = [col for col in continuous_cols if col in df_processed.columns]\n        binary_cols = [col for col in binary_cols if col in df_processed.columns]\n        categorical_cols = [col for col in categorical_cols if col in df_processed.columns]\n        \n        # Handle missing values\n        for col in continuous_cols:\n            if col in df_processed.columns:\n                if is_training:\n                    self.feature_stats[f'{col}_mean'] = df_processed[col].mean()\n                fill_value = self.feature_stats.get(f'{col}_mean', df_processed[col].mean())\n                df_processed[col].fillna(fill_value, inplace=True)\n        \n        for col in categorical_cols + binary_cols:\n            if col in df_processed.columns:\n                if is_training:\n                    mode_val = df_processed[col].mode()\n                    self.feature_stats[f'{col}_mode'] = mode_val[0] if len(mode_val) > 0 else 0\n                fill_value = self.feature_stats.get(f'{col}_mode', 0)\n                df_processed[col].fillna(fill_value, inplace=True)\n        \n        # Encode categorical variables\n        for col in categorical_cols:\n            if col in df_processed.columns:\n                if is_training:\n                    self.label_encoders[col] = LabelEncoder()\n                    df_processed[col] = self.label_encoders[col].fit_transform(df_processed[col].astype(str))\n                else:\n                    try:\n                        df_processed[col] = self.label_encoders[col].transform(df_processed[col].astype(str))\n                    except ValueError:\n                        # Handle unseen categories\n                        df_processed[col] = 0\n        \n        # Scale features\n        feature_cols = [col for col in df_processed.columns if col != 'target']\n        X = df_processed[feature_cols].values\n        \n        if is_training:\n            X_scaled = self.scaler.fit_transform(X)\n        else:\n            X_scaled = self.scaler.transform(X)\n        \n        y = df_processed['target'].values if 'target' in df_processed.columns else None\n        \n        return X_scaled, y\n\nclass MultiHeadAttention(nn.Module):\n    \"\"\"Multi-Head Self-Attention for tabular data\"\"\"\n    \n    def __init__(self, d_model, n_heads=4):\n        super().__init__()\n        self.d_model = d_model\n        self.n_heads = n_heads\n        self.d_k = d_model // n_heads\n        \n        self.W_q = nn.Linear(d_model, d_model, bias=False)\n        self.W_k = nn.Linear(d_model, d_model, bias=False)\n        self.W_v = nn.Linear(d_model, d_model, bias=False)\n        self.W_o = nn.Linear(d_model, d_model)\n        \n    def forward(self, x):\n        batch_size, seq_len, d_model = x.size()\n        \n        Q = self.W_q(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n        K = self.W_k(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n        V = self.W_v(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n        \n        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_k)\n        attn_weights = F.softmax(scores, dim=-1)\n        attn_output = torch.matmul(attn_weights, V)\n        \n        attn_output = attn_output.transpose(1, 2).contiguous().view(\n            batch_size, seq_len, d_model)\n        \n        return self.W_o(attn_output)\n\nclass FoundationModel(nn.Module):\n    \"\"\"Deep tabular neural network with attention\"\"\"\n    \n    def __init__(self, input_dim, hidden_dims=[128, 96], output_dim=32):\n        super().__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        \n        # Input processing\n        self.input_bn = nn.BatchNorm1d(input_dim)\n        self.input_dropout = nn.Dropout(0.1)\n        \n        # Projection layer for residual connection\n        self.input_proj = nn.Linear(input_dim, hidden_dims[0])\n        \n        # Layer 1: Linear transformation with residual\n        self.layer1 = nn.Linear(input_dim, hidden_dims[0])\n        self.layer1_bn = nn.BatchNorm1d(hidden_dims[0])\n        \n        # Layer 2: Multi-head attention\n        self.attention = MultiHeadAttention(hidden_dims[0], n_heads=4)\n        self.attn_norm = nn.LayerNorm(hidden_dims[0])\n        \n        # Layer 3: Compression layer\n        self.layer3 = nn.Linear(hidden_dims[0], hidden_dims[1])\n        self.layer3_bn = nn.BatchNorm1d(hidden_dims[1])\n        self.layer3_proj = nn.Linear(hidden_dims[0], hidden_dims[1])\n        \n        # Final representation layer\n        self.output_layer = nn.Linear(hidden_dims[1], output_dim)\n        \n        self._init_weights()\n    \n    def _init_weights(self):\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n                if module.bias is not None:\n                    nn.init.constant_(module.bias, 0)\n    \n    def forward(self, x):\n        # Input processing\n        x_bn = self.input_bn(x)\n        x_drop = self.input_dropout(x_bn)\n        \n        # Layer 1 with residual connection\n        h1 = F.relu(self.layer1_bn(self.layer1(x_drop)))\n        h1 = h1 + self.input_proj(x_drop)\n        \n        # Layer 2: Multi-head attention\n        h1_unsqueezed = h1.unsqueeze(1)  # Add sequence dimension\n        attn_out = self.attention(h1_unsqueezed).squeeze(1)\n        h2 = self.attn_norm(attn_out + h1)\n        \n        # Layer 3: Compression with residual\n        h3 = F.relu(self.layer3_bn(self.layer3(h2)))\n        h3 = h3 + self.layer3_proj(h2)\n        \n        # Final representation\n        output = torch.tanh(self.output_layer(h3))\n        \n        return output\n\nclass BayesianAdapter(nn.Module):\n    \"\"\"Low-rank Bayesian linear layer with Horseshoe prior\"\"\"\n    \n    def __init__(self, input_dim, output_dim, rank=8):\n        super().__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.rank = rank\n        \n        # Variational parameters for U matrix\n        self.U_mean = nn.Parameter(torch.randn(input_dim, rank) * 0.1)\n        self.U_logvar = nn.Parameter(torch.ones(input_dim, rank) * (-2))\n        \n        # Variational parameters for V matrix  \n        self.V_mean = nn.Parameter(torch.randn(output_dim, rank) * 0.1)\n        self.V_logvar = nn.Parameter(torch.ones(output_dim, rank) * (-2))\n        \n        # Global and local shrinkage parameters\n        self.tau_mean = nn.Parameter(torch.tensor(0.0))\n        self.tau_logvar = nn.Parameter(torch.tensor(-1.0))\n        \n        self.lambda_mean = nn.Parameter(torch.zeros(rank))\n        self.lambda_logvar = nn.Parameter(torch.ones(rank) * (-1))\n        \n    def sample_weights(self, num_samples=1):\n        \"\"\"Sample weight matrices using reparameterization trick\"\"\"\n        # Sample shrinkage parameters\n        tau_std = torch.exp(0.5 * self.tau_logvar)\n        tau_samples = self.tau_mean + tau_std * torch.randn(num_samples, device=self.tau_mean.device)\n        \n        lambda_std = torch.exp(0.5 * self.lambda_logvar)\n        lambda_samples = self.lambda_mean + lambda_std * torch.randn(num_samples, self.rank, device=self.lambda_mean.device)\n        \n        # Compute effective variances\n        tau_expanded = tau_samples.unsqueeze(-1)  # [num_samples, 1]\n        lambda_expanded = lambda_samples  # [num_samples, rank]\n        effective_var = tau_expanded * lambda_expanded  # [num_samples, rank]\n        \n        weights = []\n        for i in range(num_samples):\n            # Sample U and V matrices\n            U_std = torch.exp(0.5 * self.U_logvar) * effective_var[i]\n            V_std = torch.exp(0.5 * self.V_logvar) * effective_var[i]\n            \n            U_sample = self.U_mean + U_std * torch.randn_like(self.U_mean)\n            V_sample = self.V_mean + V_std * torch.randn_like(self.V_mean)\n            \n            # Compute weight matrix W = UV^T\n            W_sample = torch.mm(U_sample, V_sample.t())\n            weights.append(W_sample)\n        \n        return torch.stack(weights)\n    \n    def kl_divergence(self):\n        \"\"\"Compute KL divergence with Horseshoe prior\"\"\"\n        # KL for tau (global shrinkage)\n        tau_var = torch.exp(self.tau_logvar)\n        kl_tau = 0.5 * (tau_var + self.tau_mean**2 - 1 - self.tau_logvar)\n        \n        # KL for lambda (local shrinkage)\n        lambda_var = torch.exp(self.lambda_logvar)\n        kl_lambda = 0.5 * torch.sum(lambda_var + self.lambda_mean**2 - 1 - self.lambda_logvar)\n        \n        # KL for U and V matrices (approximated with unit variance prior)\n        U_var = torch.exp(self.U_logvar)\n        V_var = torch.exp(self.V_logvar)\n        \n        kl_U = 0.5 * torch.sum(U_var + self.U_mean**2 - 1 - self.U_logvar)\n        kl_V = 0.5 * torch.sum(V_var + self.V_mean**2 - 1 - self.V_logvar)\n        \n        return kl_tau + kl_lambda + kl_U + kl_V\n    \n    def forward(self, x, num_samples=1):\n        \"\"\"Forward pass with Monte Carlo sampling\"\"\"\n        if self.training:\n            weights = self.sample_weights(num_samples)\n            outputs = []\n            for i in range(num_samples):\n                outputs.append(torch.mm(x, weights[i]))\n            return torch.stack(outputs).mean(dim=0)\n        else:\n            # Use mean weights for inference\n            W_mean = torch.mm(self.U_mean, self.V_mean.t())\n            return torch.mm(x, W_mean)\n\nclass DistributionShiftDetector(nn.Module):\n    \"\"\"Detect and quantify distribution shift\"\"\"\n    \n    def __init__(self, input_dim, hidden_dim=64):\n        super().__init__()\n        self.classifier = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_dim // 2, 1)\n        )\n    \n    def forward(self, x):\n        return self.classifier(x)\n    \n    def compute_mmd(self, X_train, X_test, gamma=1.0):\n        \"\"\"Compute Maximum Mean Discrepancy\"\"\"\n        n, m = X_train.size(0), X_test.size(0)\n        \n        # RBF kernel computation\n        def rbf_kernel(X, Y, gamma):\n            X_norm = (X**2).sum(1).view(-1, 1)\n            Y_norm = (Y**2).sum(1).view(1, -1)\n            K = torch.exp(-gamma * (X_norm + Y_norm - 2 * torch.mm(X, Y.t())))\n            return K\n        \n        # MMD computation\n        Kxx = rbf_kernel(X_train, X_train, gamma)\n        Kyy = rbf_kernel(X_test, X_test, gamma)\n        Kxy = rbf_kernel(X_train, X_test, gamma)\n        \n        mmd_squared = (Kxx.sum() / (n * n) + Kyy.sum() / (m * m) - \n                      2 * Kxy.sum() / (n * m))\n        \n        return torch.sqrt(torch.clamp(mmd_squared, min=1e-8))\n    \n    def compute_energy_distance(self, X_train, X_test):\n        \"\"\"Compute energy distance between distributions\"\"\"\n        n, m = X_train.size(0), X_test.size(0)\n        \n        # Pairwise distances\n        def pairwise_distances(X, Y):\n            return torch.cdist(X, Y, p=2)\n        \n        # Energy distance components\n        d_xy = pairwise_distances(X_train, X_test).mean()\n        d_xx = pairwise_distances(X_train, X_train).mean()\n        d_yy = pairwise_distances(X_test, X_test).mean()\n        \n        return 2 * d_xy - d_xx - d_yy\n\nclass CalibrationSystem(nn.Module):\n    \"\"\"Temperature scaling with density ratio correction\"\"\"\n    \n    def __init__(self, num_classes=5):\n        super().__init__()\n        self.num_classes = num_classes\n        self.temperature = nn.Parameter(torch.ones(1))\n        self.density_ratio_weight = nn.Parameter(torch.tensor(0.1))\n        \n    def temperature_scale(self, logits):\n        \"\"\"Apply temperature scaling\"\"\"\n        return logits / self.temperature\n    \n    def forward(self, logits, density_ratios=None):\n        \"\"\"Apply calibration with optional density ratio correction\"\"\"\n        scaled_logits = self.temperature_scale(logits)\n        \n        if density_ratios is not None and self.training:\n            # Apply density ratio correction\n            correction = self.density_ratio_weight * torch.log(density_ratios + 1e-8)\n            scaled_logits = scaled_logits + correction.unsqueeze(-1)\n        \n        return F.softmax(scaled_logits, dim=-1)\n\nclass C2BAModel(nn.Module):\n    \"\"\"Complete Counterfactually-Calibrated Bayesian Adapter model\"\"\"\n    \n    def __init__(self, input_dim, num_classes=2, foundation_dim=32, adapter_rank=8):\n        super().__init__()\n        self.num_classes = num_classes\n        self.foundation = FoundationModel(input_dim, output_dim=foundation_dim)\n        self.bayesian_adapter = BayesianAdapter(foundation_dim, num_classes, rank=adapter_rank)\n        self.shift_detector = DistributionShiftDetector(foundation_dim)\n        self.calibration = CalibrationSystem(num_classes)\n        \n        # Store training data statistics for shift detection\n        self.register_buffer('train_features_mean', torch.zeros(foundation_dim))\n        self.register_buffer('train_features_std', torch.ones(foundation_dim))\n        \n    def forward(self, x, compute_uncertainty=True, num_mc_samples=5):\n        # Extract foundation features\n        features = self.foundation(x)\n        \n        if compute_uncertainty and self.training:\n            # Multiple forward passes for uncertainty estimation\n            predictions = []\n            for _ in range(num_mc_samples):\n                logits = self.bayesian_adapter(features, num_samples=1)\n                predictions.append(logits)\n            \n            logits = torch.stack(predictions).mean(dim=0)\n            uncertainty = torch.stack(predictions).std(dim=0).mean(dim=-1)\n        else:\n            logits = self.bayesian_adapter(features)\n            uncertainty = None\n        \n        # Detect distribution shift\n        shift_score = self.shift_detector(features).sigmoid()\n        \n        # Apply calibration\n        calibrated_probs = self.calibration(logits, shift_score)\n        \n        return {\n            'logits': logits,\n            'probabilities': calibrated_probs,\n            'features': features,\n            'shift_score': shift_score,\n            'uncertainty': uncertainty\n        }\n    \n    def compute_loss(self, outputs, targets, train_features=None):\n        \"\"\"Compute total loss including ELBO and calibration terms\"\"\"\n        logits = outputs['logits']\n        shift_scores = outputs['shift_score']\n        \n        # Classification loss\n        ce_loss = F.cross_entropy(logits, targets)\n        \n        # Bayesian adapter KL divergence\n        kl_loss = self.bayesian_adapter.kl_divergence()\n        \n        # Shift detection loss (when training data is available)\n        shift_loss = torch.tensor(0.0, device=logits.device)\n        if train_features is not None:\n            # Create labels for shift detection\n            batch_size = logits.size(0)\n            train_batch_size = train_features.size(0)\n            \n            shift_labels = torch.cat([\n                torch.zeros(train_batch_size),  # training data\n                torch.ones(batch_size)  # current batch (potentially shifted)\n            ]).to(logits.device)\n            \n            combined_features = torch.cat([train_features, outputs['features']], dim=0)\n            shift_logits = self.shift_detector(combined_features).squeeze()\n            shift_loss = F.binary_cross_entropy_with_logits(shift_logits, shift_labels)\n        \n        # Total loss with weighting\n        total_loss = ce_loss + 0.01 * kl_loss + 0.5 * shift_loss\n        \n        return {\n            'total_loss': total_loss,\n            'ce_loss': ce_loss,\n            'kl_loss': kl_loss,\n            'shift_loss': shift_loss\n        }\n\nclass ModelTrainer:\n    \"\"\"Comprehensive training pipeline for C²BA model\"\"\"\n    \n    def __init__(self, model, device='cpu'):\n        self.model = model.to(device)\n        self.device = device\n        self.best_val_loss = float('inf')\n        self.patience_counter = 0\n        \n    def train_epoch(self, train_loader, optimizer, kl_weight=1.0):\n        \"\"\"Train for one epoch\"\"\"\n        self.model.train()\n        total_loss = 0\n        correct = 0\n        total = 0\n        \n        for batch_idx, (data, targets) in enumerate(train_loader):\n            data, targets = data.to(self.device), targets.to(self.device)\n            \n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = self.model(data, compute_uncertainty=True)\n            \n            # Compute losses\n            loss_dict = self.model.compute_loss(outputs, targets)\n            \n            # Apply KL annealing\n            loss_dict['total_loss'] = (loss_dict['ce_loss'] + \n                                     kl_weight * loss_dict['kl_loss'] + \n                                     loss_dict['shift_loss'])\n            \n            # Backward pass\n            loss_dict['total_loss'].backward()\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n            optimizer.step()\n            \n            # Statistics\n            total_loss += loss_dict['total_loss'].item()\n            pred = outputs['probabilities'].argmax(dim=1)\n            correct += pred.eq(targets).sum().item()\n            total += targets.size(0)\n            \n        return {\n            'loss': total_loss / len(train_loader),\n            'accuracy': 100. * correct / total\n        }\n    \n    def evaluate(self, val_loader):\n        \"\"\"Evaluate model on validation set\"\"\"\n        self.model.eval()\n        val_loss = 0\n        correct = 0\n        total = 0\n        all_probs = []\n        all_targets = []\n        \n        with torch.no_grad():\n            for data, targets in val_loader:\n                data, targets = data.to(self.device), targets.to(self.device)\n                \n                outputs = self.model(data, compute_uncertainty=False)\n                loss_dict = self.model.compute_loss(outputs, targets)\n                \n                val_loss += loss_dict['total_loss'].item()\n                pred = outputs['probabilities'].argmax(dim=1)\n                correct += pred.eq(targets).sum().item()\n                total += targets.size(0)\n                \n                all_probs.extend(outputs['probabilities'].cpu().numpy())\n                all_targets.extend(targets.cpu().numpy())\n        \n        all_probs = np.array(all_probs)\n        all_targets = np.array(all_targets)\n        \n        # Compute additional metrics\n        pred_classes = np.argmax(all_probs, axis=1)\n        f1 = f1_score(all_targets, pred_classes, average='weighted')\n        \n        return {\n            'loss': val_loss / len(val_loader),\n            'accuracy': 100. * correct / total,\n            'f1_score': f1,\n            'predictions': all_probs,\n            'targets': all_targets\n        }\n    \n    def train(self, train_loader, val_loader, num_epochs=100, patience=10):\n        \"\"\"Complete training loop with early stopping\"\"\"\n        # Optimizer with different learning rates for different components\n        foundation_params = list(self.model.foundation.parameters())\n        adapter_params = list(self.model.bayesian_adapter.parameters())\n        other_params = (list(self.model.shift_detector.parameters()) + \n                       list(self.model.calibration.parameters()))\n        \n        optimizer = torch.optim.AdamW([\n            {'params': foundation_params, 'lr': 1e-3},\n            {'params': adapter_params, 'lr': 5e-3},\n            {'params': other_params, 'lr': 1e-3}\n        ], weight_decay=1e-5)\n        \n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n            optimizer, T_max=num_epochs, eta_min=1e-6)\n        \n        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n        \n        for epoch in range(num_epochs):\n            # KL annealing\n            kl_weight = min(1.0, epoch / 50.0)\n            \n            # Training\n            train_stats = self.train_epoch(train_loader, optimizer, kl_weight)\n            \n            # Validation\n            val_stats = self.evaluate(val_loader)\n            \n            # Learning rate scheduling\n            scheduler.step()\n            \n            # Record history\n            history['train_loss'].append(train_stats['loss'])\n            history['train_acc'].append(train_stats['accuracy'])\n            history['val_loss'].append(val_stats['loss'])\n            history['val_acc'].append(val_stats['accuracy'])\n            \n            # Early stopping\n            if val_stats['loss'] < self.best_val_loss:\n                self.best_val_loss = val_stats['loss']\n                self.patience_counter = 0\n                # Save best model\n                torch.save(self.model.state_dict(), 'best_c2ba_model.pt')\n            else:\n                self.patience_counter += 1\n                \n            if self.patience_counter >= patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n                \n            if (epoch + 1) % 10 == 0:\n                print(f'Epoch {epoch+1}/{num_epochs}:')\n                print(f'  Train Loss: {train_stats[\"loss\"]:.4f}, Train Acc: {train_stats[\"accuracy\"]:.2f}%')\n                print(f'  Val Loss: {val_stats[\"loss\"]:.4f}, Val Acc: {val_stats[\"accuracy\"]:.2f}%')\n                print(f'  Val F1: {val_stats[\"f1_score\"]:.4f}')\n        \n        # Load best model\n        self.model.load_state_dict(torch.load('best_c2ba_model.pt'))\n        \n        return history\n\nclass MetricsCalculator:\n    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n    \n    @staticmethod\n    def expected_calibration_error(y_prob, y_true, n_bins=10):\n        \"\"\"Calculate Expected Calibration Error (ECE)\"\"\"\n        bin_boundaries = np.linspace(0, 1, n_bins + 1)\n        bin_lowers = bin_boundaries[:-1]\n        bin_uppers = bin_boundaries[1:]\n        \n        ece = 0\n        for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n            # Find samples in bin\n            in_bin = (y_prob > bin_lower) & (y_prob <= bin_upper)\n            prop_in_bin = in_bin.mean()\n            \n            if prop_in_bin > 0:\n                accuracy_in_bin = y_true[in_bin].mean()\n                avg_confidence_in_bin = y_prob[in_bin].mean()\n                ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n        \n        return ece\n    \n    @staticmethod\n    def brier_score(y_prob, y_true, num_classes):\n        \"\"\"Calculate Brier Score\"\"\"\n        y_true_onehot = np.eye(num_classes)[y_true]\n        return np.mean(np.sum((y_prob - y_true_onehot)**2, axis=1))\n    \n    @staticmethod\n    def compute_comprehensive_metrics(y_prob, y_true, num_classes=5):\n        \"\"\"Compute all evaluation metrics\"\"\"\n        y_pred = np.argmax(y_prob, axis=1)\n        y_prob_max = np.max(y_prob, axis=1)\n        y_true_binary = (y_pred == y_true).astype(int)\n        \n        # Classification metrics\n        accuracy = accuracy_score(y_true, y_pred)\n        f1 = f1_score(y_true, y_pred, average='weighted')\n        \n        # Calibration metrics\n        ece = MetricsCalculator.expected_calibration_error(y_prob_max, y_true_binary)\n        brier = MetricsCalculator.brier_score(y_prob, y_true, num_classes)\n        \n        # Confidence metrics\n        avg_confidence = np.mean(y_prob_max)\n        confidence_std = np.std(y_prob_max)\n        \n        return {\n            'accuracy': accuracy,\n            'f1_score': f1,\n            'ece': ece,\n            'brier_score': brier,\n            'avg_confidence': avg_confidence,\n            'confidence_std': confidence_std\n        }\n\ndef create_distribution_shifts(X, y, shift_type='age'):\n    \"\"\"Create different types of distribution shifts - adapted for binary classification\"\"\"\n    \n    if shift_type == 'age':\n        # Age-based split (assuming age is first column after scaling)\n        # Use median split\n        age_median = np.median(X[:, 0])  # Age is typically first feature\n        train_mask = X[:, 0] <= age_median  # Younger patients for training\n        test_mask = X[:, 0] > age_median    # Older patients for testing\n    \n    elif shift_type == 'gender':\n        # Gender-based split (assuming sex is in features)\n        # Find sex column (should be binary 0/1)\n        sex_col = None\n        for i in range(min(10, X.shape[1])):  # Check first 10 features\n            unique_vals = np.unique(X[:, i])\n            if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1}):\n                sex_col = i\n                break\n        \n        if sex_col is not None:\n            # Create gender imbalance\n            male_indices = np.where(X[:, sex_col] > 0.5)[0]  # After scaling, male might not be exactly 1\n            female_indices = np.where(X[:, sex_col] <= 0.5)[0]\n            \n            # Train: 70% male, Test: balanced\n            n_train = len(X) // 2\n            if len(male_indices) > 0 and len(female_indices) > 0:\n                train_male_count = min(int(0.7 * n_train), len(male_indices))\n                train_female_count = min(n_train - train_male_count, len(female_indices))\n                \n                train_indices = np.concatenate([\n                    np.random.choice(male_indices, train_male_count, replace=False),\n                    np.random.choice(female_indices, train_female_count, replace=False)\n                ])\n                \n                train_mask = np.zeros(len(X), dtype=bool)\n                train_mask[train_indices] = True\n                test_mask = ~train_mask\n            else:\n                # Fallback to random split\n                train_mask = np.random.random(len(X)) < 0.6\n                test_mask = ~train_mask\n        else:\n            # Fallback to random split\n            train_mask = np.random.random(len(X)) < 0.6\n            test_mask = ~train_mask\n    \n    elif shift_type == 'severity':\n        # Severity-based split for binary classification\n        # Train on one class predominantly, test on balanced\n        positive_indices = np.where(y == 1)[0]\n        negative_indices = np.where(y == 0)[0]\n        \n        if len(positive_indices) > 0 and len(negative_indices) > 0:\n            # Train: 80% negative cases (mild), Test: balanced\n            n_train = len(X) // 2\n            train_neg_count = min(int(0.8 * n_train), len(negative_indices))\n            train_pos_count = min(n_train - train_neg_count, len(positive_indices))\n            \n            train_indices = np.concatenate([\n                np.random.choice(negative_indices, train_neg_count, replace=False),\n                np.random.choice(positive_indices, train_pos_count, replace=False)\n            ])\n            \n            train_mask = np.zeros(len(X), dtype=bool)\n            train_mask[train_indices] = True\n            test_mask = ~train_mask\n        else:\n            # Fallback to random split\n            train_mask = np.random.random(len(X)) < 0.6\n            test_mask = ~train_mask\n    \n    elif shift_type == 'feature':\n        # Feature-based shift: split based on a continuous feature\n        # Use cholesterol or blood pressure if available\n        feature_col = min(2, X.shape[1] - 1)  # Use 3rd feature (likely chol or trestbps)\n        feature_median = np.median(X[:, feature_col])\n        train_mask = X[:, feature_col] <= feature_median\n        test_mask = X[:, feature_col] > feature_median\n    \n    else:\n        # Random split as baseline\n        train_mask = np.random.random(len(X)) < 0.6\n        test_mask = ~train_mask\n    \n    # Ensure both sets have both classes for binary classification\n    train_classes = np.unique(y[train_mask])\n    test_classes = np.unique(y[test_mask])\n    \n    if len(train_classes) < 2 or len(test_classes) < 2:\n        print(\"⚠ Warning: Unbalanced class distribution detected. Using stratified split.\")\n        # Fallback to stratified split\n        train_indices, test_indices = train_test_split(\n            np.arange(len(X)), test_size=0.4, random_state=42, stratify=y\n        )\n        train_mask = np.zeros(len(X), dtype=bool)\n        test_mask = np.zeros(len(X), dtype=bool)\n        train_mask[train_indices] = True\n        test_mask[test_indices] = True\n    \n    return train_mask, test_mask\n\ndef load_and_preprocess_data():\n    \"\"\"Load and preprocess UCI Heart Disease dataset\"\"\"\n    # Load the heart disease dataset\n    df = load_heart_disease_data()\n    \n    print(f\"Dataset shape: {df.shape}\")\n    print(f\"Columns: {list(df.columns)}\")\n    \n    # Display basic statistics\n    target_col = 'target' if 'target' in df.columns else 'num'\n    if target_col in df.columns:\n        print(f\"Target distribution: {df[target_col].value_counts().sort_index().to_dict()}\")\n    \n    # If we have a multi-class target (num column), convert to binary for this implementation\n    if 'num' in df.columns and df['num'].max() > 1:\n        # Convert multi-class to binary (0 = no disease, 1+ = disease)\n        df['target'] = (df['num'] > 0).astype(int)\n        print(f\"Converted to binary classification. New target distribution: {df['target'].value_counts().to_dict()}\")\n    elif 'target' not in df.columns:\n        # If no target column exists, create one for demonstration\n        print(\"No target column found, creating synthetic target...\")\n        np.random.seed(42)\n        # Create realistic target based on some features\n        if 'age' in df.columns and 'cp' in df.columns:\n            risk_score = (df['age'] - df['age'].mean()) / df['age'].std()\n            if 'cp' in df.columns:\n                risk_score += 0.5 * (df['cp'] == df['cp'].mode()[0])\n            df['target'] = (risk_score > 0).astype(int)\n        else:\n            df['target'] = np.random.binomial(1, 0.45, len(df))\n        print(f\"Created synthetic target distribution: {df['target'].value_counts().to_dict()}\")\n    \n    return df\n\ndef main():\n    \"\"\"Main training and evaluation pipeline\"\"\"\n    print(\"=== C²BA Heart Disease Classification ===\")\n    print(\"Loading and preprocessing data...\")\n    \n    # Load data\n    df = load_and_preprocess_data()\n    print(f\"Dataset shape: {df.shape}\")\n    print(f\"Class distribution: {df['num'].value_counts().sort_index().to_dict()}\")\n    \n    # Initialize data processor\n    processor = DataProcessor()\n    \n    # Preprocess data\n    X, y = processor.preprocess_data(df, is_training=True)\n    \n    print(f\"Preprocessed feature shape: {X.shape}\")\n    print(f\"Number of classes: {len(np.unique(y))}\")\n    \n    # Create distribution shift\n    train_mask, test_mask = create_distribution_shifts(X, y, shift_type='geographical')\n    \n    X_train_shift, y_train_shift = X[train_mask], y[train_mask]\n    X_test_shift, y_test_shift = X[test_mask], y[test_mask]\n    \n    # Standard train/validation split on shifted training data\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_train_shift, y_train_shift, test_size=0.2, random_state=42, stratify=y_train_shift\n    )\n    \n    print(f\"Training set: {X_train.shape[0]} samples\")\n    print(f\"Validation set: {X_val.shape[0]} samples\")\n    print(f\"Test set (shifted): {X_test_shift.shape[0]} samples\")\n    \n    # Create datasets and data loaders\n    train_dataset = HeartDiseaseDataset(X_train, y_train)\n    val_dataset = HeartDiseaseDataset(X_val, y_val)\n    test_dataset = HeartDiseaseDataset(X_test_shift, y_test_shift)\n    \n    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n    \n    # Initialize model\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    model = C2BAModel(\n        input_dim=X_train.shape[1],\n        num_classes=5,\n        foundation_dim=32,\n        adapter_rank=8\n    )\n    \n    # Initialize trainer\n    trainer = ModelTrainer(model, device=device)\n    \n    print(\"\\n=== Training Phase ===\")\n    history = trainer.train(train_loader, val_loader, num_epochs=100, patience=15)\n    \n    print(\"\\n=== Evaluation Phase ===\")\n    \n    # Evaluate on validation set\n    print(\"Validation Set Evaluation:\")\n    val_results = trainer.evaluate(val_loader)\n    val_metrics = MetricsCalculator.compute_comprehensive_metrics(\n        val_results['predictions'], val_results['targets']\n    )\n    \n    for metric, value in val_metrics.items():\n        print(f\"  {metric}: {value:.4f}\")\n    \n    # Evaluate on test set (distribution shifted)\n    print(\"\\nTest Set Evaluation (Distribution Shifted):\")\n    test_results = trainer.evaluate(test_loader)\n    test_metrics = MetricsCalculator.compute_comprehensive_metrics(\n        test_results['predictions'], test_results['targets']\n    )\n    \n    for metric, value in test_metrics.items():\n        print(f\"  {metric}: {value:.4f}\")\n    \n    # Distribution shift analysis\n    print(\"\\n=== Distribution Shift Analysis ===\")\n    \n    # Compute shift detection metrics\n    model.eval()\n    with torch.no_grad():\n        # Get features from both sets\n        train_features_list = []\n        test_features_list = []\n        \n        for data, _ in val_loader:\n            data = data.to(device)\n            outputs = model(data, compute_uncertainty=False)\n            train_features_list.append(outputs['features'].cpu())\n        \n        for data, _ in test_loader:\n            data = data.to(device)\n            outputs = model(data, compute_uncertainty=False)\n            test_features_list.append(outputs['features'].cpu())\n        \n        train_features = torch.cat(train_features_list, dim=0)\n        test_features = torch.cat(test_features_list, dim=0)\n    \n    # Compute MMD\n    shift_detector = model.shift_detector\n    mmd_score = shift_detector.compute_mmd(train_features, test_features).item()\n    energy_distance = shift_detector.compute_energy_distance(train_features, test_features).item()\n    \n    print(f\"Maximum Mean Discrepancy: {mmd_score:.6f}\")\n    print(f\"Energy Distance: {energy_distance:.6f}\")\n    \n    # Performance degradation analysis\n    accuracy_drop = val_metrics['accuracy'] - test_metrics['accuracy']\n    calibration_degradation = test_metrics['ece'] - val_metrics['ece']\n    \n    print(f\"\\nPerformance Impact:\")\n    print(f\"  Accuracy drop: {accuracy_drop:.2f}%\")\n    print(f\"  Calibration degradation (ECE): {calibration_degradation:.4f}\")\n    print(f\"  F1-score drop: {val_metrics['f1_score'] - test_metrics['f1_score']:.4f}\")\n    \n    # Uncertainty quantification analysis\n    print(\"\\n=== Uncertainty Quantification Analysis ===\")\n    \n    # Get uncertainty estimates\n    model.eval()\n    uncertainties = []\n    confidences = []\n    correct_preds = []\n    \n    with torch.no_grad():\n        for data, targets in test_loader:\n            data, targets = data.to(device), targets.to(device)\n            outputs = model(data, compute_uncertainty=True, num_mc_samples=10)\n            \n            probs = outputs['probabilities'].cpu().numpy()\n            preds = np.argmax(probs, axis=1)\n            confidence = np.max(probs, axis=1)\n            correct = (preds == targets.cpu().numpy()).astype(int)\n            \n            if outputs['uncertainty'] is not None:\n                uncertainties.extend(outputs['uncertainty'].cpu().numpy())\n            confidences.extend(confidence)\n            correct_preds.extend(correct)\n    \n    confidences = np.array(confidences)\n    correct_preds = np.array(correct_preds)\n    \n    # Analyze uncertainty-accuracy relationship\n    if uncertainties:\n        uncertainties = np.array(uncertainties)\n        # Correlation between uncertainty and correctness\n        uncertainty_accuracy_corr = np.corrcoef(uncertainties, 1 - correct_preds)[0, 1]\n        print(f\"Uncertainty-Error Correlation: {uncertainty_accuracy_corr:.4f}\")\n        \n        # High uncertainty samples statistics\n        high_uncertainty_threshold = np.percentile(uncertainties, 80)\n        high_uncertainty_mask = uncertainties > high_uncertainty_threshold\n        high_uncertainty_accuracy = correct_preds[high_uncertainty_mask].mean()\n        \n        print(f\"High Uncertainty Samples Accuracy: {high_uncertainty_accuracy:.4f}\")\n    \n    # Confidence-accuracy relationship\n    confidence_accuracy_corr = np.corrcoef(confidences, correct_preds)[0, 1]\n    print(f\"Confidence-Accuracy Correlation: {confidence_accuracy_corr:.4f}\")\n    \n    # Calibration reliability diagram\n    print(\"\\n=== Calibration Reliability Analysis ===\")\n    \n    # Bin predictions by confidence\n    n_bins = 10\n    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n    \n    print(\"Confidence Bin | Accuracy | Count | ECE Contribution\")\n    print(\"-\" * 55)\n    \n    total_ece_contribution = 0\n    for i in range(n_bins):\n        bin_lower = bin_boundaries[i]\n        bin_upper = bin_boundaries[i + 1]\n        \n        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n        \n        if in_bin.sum() > 0:\n            bin_accuracy = correct_preds[in_bin].mean()\n            bin_confidence = confidences[in_bin].mean()\n            bin_count = in_bin.sum()\n            bin_weight = bin_count / len(confidences)\n            ece_contribution = abs(bin_confidence - bin_accuracy) * bin_weight\n            total_ece_contribution += ece_contribution\n            \n            print(f\"{bin_lower:.1f}-{bin_upper:.1f}     | {bin_accuracy:.3f}    | {bin_count:5d} | {ece_contribution:.4f}\")\n    \n    print(\"-\" * 55)\n    print(f\"Total ECE: {total_ece_contribution:.4f}\")\n    \n    # Save results summary\n    results_summary = {\n        'validation_metrics': val_metrics,\n        'test_metrics': test_metrics,\n        'distribution_shift': {\n            'mmd_score': mmd_score,\n            'energy_distance': energy_distance,\n            'accuracy_drop': accuracy_drop,\n            'calibration_degradation': calibration_degradation\n        },\n        'uncertainty_analysis': {\n            'confidence_accuracy_correlation': confidence_accuracy_corr,\n        }\n    }\n    \n    if uncertainties:\n        results_summary['uncertainty_analysis'].update({\n            'uncertainty_accuracy_correlation': uncertainty_accuracy_corr,\n            'high_uncertainty_accuracy': high_uncertainty_accuracy\n        })\n    \n    print(\"\\n=== Training Complete ===\")\n    print(\"Model saved as 'best_c2ba_model.pt'\")\n    print(\"\\nKey Findings:\")\n    print(f\"- Base model accuracy: {val_metrics['accuracy']:.2f}%\")\n    print(f\"- Shifted data accuracy: {test_metrics['accuracy']:.2f}%\")\n    print(f\"- Calibration quality (ECE): {test_metrics['ece']:.4f}\")\n    print(f\"- Distribution shift detected (MMD): {mmd_score:.6f}\")\n    \n    if test_metrics['accuracy'] > val_metrics['accuracy'] * 0.9:  # Less than 10% drop\n        print(\"✓ Model shows good robustness to distribution shift\")\n    else:\n        print(\"⚠ Significant performance degradation detected\")\n    \n    if test_metrics['ece'] < 0.1:  # Well-calibrated\n        print(\"✓ Model maintains good calibration under shift\")\n    else:\n        print(\"⚠ Calibration degraded under distribution shift\")\n    \n    return results_summary, model, trainer\n\nif __name__ == \"__main__\":\n    # Run the complete pipeline\n    results, trained_model, trainer = main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T18:35:46.458294Z","iopub.execute_input":"2025-09-27T18:35:46.458937Z","iopub.status.idle":"2025-09-27T18:35:46.692552Z","shell.execute_reply.started":"2025-09-27T18:35:46.458911Z","shell.execute_reply":"2025-09-27T18:35:46.691696Z"}},"outputs":[{"name":"stdout","text":"=== C²BA Heart Disease Classification ===\nLoading and preprocessing data...\n✓ Successfully loaded data from: /kaggle/input/heart-disease-data/heart_disease_uci.csv\nDataset shape: (920, 16)\nColumns: ['id', 'age', 'sex', 'dataset', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\nTarget distribution: {0: 411, 1: 265, 2: 109, 3: 107, 4: 28}\nConverted to binary classification. New target distribution: {1: 509, 0: 411}\nDataset shape: (920, 17)\nClass distribution: {0: 411, 1: 265, 2: 109, 3: 107, 4: 28}\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3324545110.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[0;31m# Run the complete pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/3324545110.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0;31m# Preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Preprocessed feature shape: {X.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3324545110.py\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(self, df, is_training)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'target'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mmax_target_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_target_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0mmax_target_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_target_value\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Now comparing scalar values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."],"ename":"ValueError","evalue":"The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}